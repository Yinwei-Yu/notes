> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/b4_QqfoPzH5EoG329ic--w)

这两天在网上刷到了一张图，很有意思。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZgKE2XsHczxKck5OiaicwwxKiawJvV1nYp85fn8DGltVNrB3JohBeL9ybw/640?wx_fmt=png&from=appmsg#imgIndex=0)

其实就是一张经典的视觉错觉图，做了个漂浮的心形图案。

如果你用电脑打开这篇文章的话，没看到这个图动起来的话，那就就用手机打开或者直接把页面缩小。

瞬间，你就能看到这个图里的爱心，直接左右横跳起来了。。。

看到的兄弟可以把公屏打在弹幕上。

这哥们说，这是最好的 AI 探测器，说，没有 AI 能看到这个图中间还有个爱心。

我顺手找了几个模型试试，结果无一例外，果然，没一个 AI 认出来。

比如 Gemini 2.5 Pro，率先翻车。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZX2bBfOcWfuLbwrlueia7NAJmI1Uibym4vTMuK71COibibfwjM9ZgkKgQ0A/640?wx_fmt=png&from=appmsg#imgIndex=1)

给我扯了一堆有的没的，然后说了一句，圆圈。

圈你妹 = =

GPT-5-Thinking，想了 2 分多分钟，直接阵亡。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZvpVyvsDtjm3hLoB4ekSriaCuy139GoFKWtIPH2N354fNSiafJqcjIJfg/640?wx_fmt=png&from=appmsg#imgIndex=2)

甚至，我还试了一下豪华版 GPT-5 Pro。

在长达 7 分钟的花里胡哨之后，宣布直接躺平。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZIy83OibSgSR8HdwbIdCct2OMfJAFElmJvdpnNLnMibTLcIVlicSNGFPeA/640?wx_fmt=png&from=appmsg#imgIndex=3)

国产三巨头，豆包、Qwen、元宝，也都倒在了这张图的淫威之下。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZCgv7Y7qSibpZvNs8XhNWCDAibOmjWpM6g215rr3D6z8TTrRND30dP14Q/640?wx_fmt=png&from=appmsg#imgIndex=4)

DeepSeek 因为没有多模态，所以反而逃过一劫。

在这测试过程中，我一度产生了一种错觉，就是，不会这些模型，不知道啥叫心形吧。

导致我非常智障的还去问了一下。。。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZD1Y9I7pUnXP3JQ8cp4udViaGtBRPMzEAh3jb2icbqouMFQ5Bgt8cFJ1Q/640?wx_fmt=png&from=appmsg#imgIndex=5)

认识，看来没啥问题。。。

你们也能看到，我用的都是同一套提示词。

我觉得，同样的问题交给随便的一个人，应该都是能得出正确答案的。

所以，我就产生了很强的好奇。

这到底是什么？

再抽空花了一晚上的时间，去 DeepReaserch 和研究之后，我看到了一篇 AI 这块超级好玩的论文。

是今年 5 月发的，叫《Time Blindness: Why Video-Language Models Can’t See What Humans Can?》

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZ7nDkJOzKEIJTTQPjK65ich2316YAG03fRXNgPMXPyiatR3M8muD6KSDw/640?wx_fmt=png&from=appmsg#imgIndex=6)

真的，AI 研究到后面，怎么发现，研究的全是人类。。。

这个标题翻译过来大概就是：

为什么视觉语言模型看不到人类能看到的东西？

虽然文中的例子是视频，跟我们上文的爱心图有点不太一样，但是底层原理，其实在我读完以后看来，是完全一脉相通的。

这项研究设置了一个基准，叫做 SpookyBench，合成了一堆由噪点组成的视频，是黑白的。

[视频详情](javascript:;)

你只要一暂停，就啥也看不到了。

还有很多类似的。

![](https://mmbiz.qpic.cn/mmbiz_gif/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZ0CicRddPJNfu2orNL5CTfc8MHztkiaeVrBeumVvXdkhO4RgLwg9frNqw/640?wx_fmt=gif&from=appmsg#imgIndex=7)

这篇论文就拿 451 个这样的视频，组成了一个基准，去视觉大模型进行测试。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZVbmunhYCDf13QdYae8Vc6S1Ul5buJvtz2jWq0D5rfl0Y4bh4tT5JHQ/640?wx_fmt=png&from=appmsg#imgIndex=8)

结果就是，非常的喜闻乐见。

人类可以毫不费力地识别出这些视频中的形状、文本和图案，准确率超过 98%。

而大模型的准确率，为 0%。

全军覆没，无一幸免。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZtTuSibuCHQ6Rhgqp5mDavX857jvzoMa9L2dySs3tSBclG5fjcAibVMUA/640?wx_fmt=png&from=appmsg#imgIndex=9)

我已经很久很久没见过这么多的 0 分了。

太特么赤鸡了。

无论模型架构大小、训练数据规模、是否经过微调或采用何种提示策略，AI 从未答对任何一段视频的内容。

我也拿几个模型去试了一下，同样的那头鹿的视频，Gemini2.5-Pro 同样无法识别。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZdSzuV2E4RCwSJgjNM2n1TT5iaiciaNtPgj47HcTNiapXZRQyScolMB0Uicw/640?wx_fmt=png&from=appmsg#imgIndex=10)

原因其实特别简单。

**AI 是空间维度上的王者，但却是时间维度上的瞎子。**

我这么说可能会有点难以理解。

我们可以先想想，现在所有的大模型，包括 GPT-5、Gemini 2.5 Pro，它们是怎么看视频的。

很多人以为他们跟人一样，就是搬个小板凳搁那坐着，目不转睛的看完了整个视频？

错了，不是这样的。

现在大模型的主流做法，本质上不是看视频，是看照片。

它们会从视频里，每隔一段时间抽帧，也就是截取几张静态的图片。 比如，第 1 秒截一张，第 1.5 秒截一张，第 2 秒截一张等等等等。

然后，AI 会用它那分析静态图片（也就是空间信息）的能力，去分析这些所有的照片。

“哦，这张照片里有噪点。” “哦，这张照片里还是噪点。” “哦，这张照片里依然是噪点。”

最后，它得出结论： “这特么就是个噪点视频。”

**这就是最本质的问题所有，AI 彻底丢掉了所有的帧与帧之间的信息。**

而那个 “漂浮的心形” 和“噪点中的鹿”，其实本质上，它们的信息恰恰_只_存在于帧与帧之间。 

这其实，就是，_时间维度_。

在任何一个单独的瞬间，心形和鹿都是不存在的，都是不可见的。

你只有把这些瞬间_连续播放_，让时间流动起来，你才能看到他们。

突然想起了以前做交互设计的时候，有一个几乎刻在我血液里的心理学，这玩意，叫格式塔心理学。

几乎就是用户体验行业的基石之一。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZJI1zCKDdibjxTLDLa5oX8LXcdKxO9OkzicVez0sH8icvIKXRicVRqFsITA/640?wx_fmt=png&from=appmsg#imgIndex=11)

里面有一个非常牛逼的原则，叫 “**共同命运法则**”（Law of Common Fate）。

这个法则是说，我们的大脑会本能地、自动地、不讲道理地，把朝着同一方向运动的物体，识别为一个_整体_。

![](https://mmbiz.qpic.cn/mmbiz_gif/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZaOCXRIUYibscRymYw7jPOHubvj6bWoRvEbpOgmIwZB4dhIznMJ8oT4g/640?wx_fmt=gif&from=appmsg#imgIndex=12)

这玩意几乎就是刻在我们的史前基因里面的。

比如在几万年前的草原上，我们的老祖宗 “智人坤坤”，正蹲在草丛里。

他眼前是一片随风摆动的、杂乱的灌木。

突然，在灌木丛中，有一小片叶子的摆动方式，跟周围所有的叶子都_不一样，_它们在以一个相同的规律，朝着同一个方向（比如坤坤的方向）缓慢移动。

坤坤的大脑，甚至不需要他思考，就会立刻拉响警报： “卧槽！快跑！老虎来了！！！有危险！！”

那些 “共同运动” 的像素点，在坤坤的大脑里自动组合成了老虎这个整体。

所以，你看，当你看到那个 “噪点鹿” 的视频时，你根本不需要努力，你大脑里的共同命运法则就自动启动了。

它帮你把所有一起往上移动的噪点归为一类，识别为 “鹿”，把所有一起往下移动的噪点归为另一类，识别为 “背景”。

你之所以能看到鹿，不是因为你_看见_了鹿，而是因为你_看见_了运动本身。

**但 AI 不行。****它没有我们这套 “共同命运法则” 的视觉系统。**

它的架构，论文里叫 "Spatial Bias" 空间偏见，决定了它只能先去识别空间上的特征。

它看每一帧，都是一堆杂乱无章的噪点。

但它无法从时间的维度上，去发现这些噪点之间 “共同的命运”，所以，它看不到那只鹿。

这个问题，在论文中，被称为。

时间盲视，Time Blindness。

目前看，好像没有啥解决办法，不仅仅是一个技术漏洞了，或者一个可以喂数据就能解决的小 bug，论文里也试了，微调训练也没用。

**我们活在流中，而 AI 活在帧中。**

这个世界对我们来说，首先是连续的、流动的、充满_过程_的。 

而对 AI 来说，这个世界首先是离散的、静态的、充满_物体_的。

太有意思了，这是我最近，看到的最哲学最让我喜欢的一段表述。

我们现在理解了噪点，让我们回到最开始的爱心。

这时候，我其实又产生了问题，不对啊，运动这事，是时间维度的，但是那个爱心，明明就是一张图，根本没有时间属性，那这玩意，到底为啥也能让人感觉到，动呢？？？

![](https://mmbiz.qpic.cn/mmbiz_jpg/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZVJZEYlR1kXMXRf3gKZLSpUAJjib3LOGoWy7exsrlGha8oPia8GUwRJicQ/640?wx_fmt=jpeg&from=appmsg#imgIndex=13)

我没理解，于是，我又进行了新一轮的研究。。。

结果，答案居然让我有点无语。。。

答案特别简单，就是因为：

因为我们自己会动。

还是，不受控制地动。。。

在 20 世纪 50 年代，眼动领域有一个实验证明了一个事情，就是，人眼在注视时并非完全静止，而是不断进行微小的运动。

正是这些不自主的眼球运动，保证了我们对静止图像的持续感知。

这样的视错觉图，基本上都是利用了我们这个会自己运动的特征，来做出动态效果的。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZz2Zugf09O3gicIicc2D5HoLf1iaUHBSgOB1kUc6mHMhIOxlTMHKRXYWZg/640?wx_fmt=png&from=appmsg#imgIndex=14)

为了使人类能够看见，视网膜上的图像必须持续发生一定程度的运动。

反过来讲，如果某个视野（无论其大小、颜色或亮度）保持严格的静止，那么在 1~3 秒内，该区域就会在视野中逐渐消失**。**

视觉科学里有个差不多的理论是特克斯勒消逝效应，说的是当人们长时间注视一个固定点时，周边视野中不变的刺激会逐渐淡化甚至消失。

听起来挺绕的，但如果你想试一下，刻意控制眼球静止不动的话，你可以放大这张图，然后刻意的牢牢盯住中间的十字。

应该可以感觉到十字周围的颜色在慢慢消失，然后变成一片灰白色。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURq8G8EiaJ0ia0CGWSoC9N8AhZLrNgyPHENqq0FwsuIt2Lrn6FFQh1nYiaT1qOJMrCzibxdicU3ZHicibLHNQ/640?wx_fmt=png&from=appmsg#imgIndex=15)

这就是著名的特克斯勒消逝效应的哲学。

没有变化，则等于没有信息。

这篇文章写着写着，突然感觉回到了 7、8 年前还在做用户体验设计的时候，天天研究认知心理学的日子。

那时候，我们天天在研究人，研究认知心理学，研究人的行为、研究人的眼动路线、研究人的注意力、研究人的记忆，就想着，我们的产品，怎么让用户体验更丝滑一点，让他更爽一点，我们的转化率更高一点。。。

没想到这么多年以后，天天研究 AI，发现到头来。

又回到了当年。

原来当年研究了那么久的知识，在如今的时代，又以另一种路径，穿越了时空，散发出了新的光彩。

AI 跟人，也真的都是超级有趣的物种。

在无数路径上殊途同归，却又在各自的路线上，分道扬镳。

但我还是更喜欢人一点。

毕竟，我们不仅能看到噪点中的鹿，我们还能看到沉默中的爱，看到无常中的美。

还有，那时间。

流逝的本身。

******以上，既然看到这里了，如果觉得不错，随手点个赞、在看、转发三连吧，如果想第一时间收到推送，也可以给我个星标⭐～谢谢你看我的文章，我们，下次再见。******

>/ 作者：卡兹克

>/ 投稿或爆料，请联系邮箱：wzglyay@virxact.com